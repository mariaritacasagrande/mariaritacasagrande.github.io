---
layout: post
title: Algoritimos, Inteligencia artificial e mulheres - Quando a História se repete!
featured: true
author: ahmad
tags: [frontpage, jekyll, blog]
image: '/images/posts/algoritmo-mujeres.jpg'
---

Temos que ensinar que a tecnologia não tem gênero. Enquanto repetimos essa frase como um mantra, os algoritmos já causaram muitos danos. No artigo anterior Algoritmos e inteligência artificial: Por onde começar ?, Referia-se ao uso de dados sujos pela polícia americana, que reforçava práticas discriminatórias. Esse é um grande problema que nos leva a pensar que por trás de cada algoritmo há dados, dados introduzidos por indivíduos, muitas vezes com seus próprios interesses. Exemplos como esse aparecem nos noticiários quase todos os dias. Não se surpreenda, portanto, com os resultados quando começarmos a investigar o papel das mulheres diante das novas tecnologias e particularmente diante dos algoritmos.


>Acreditar que ganhamos a guerra da igualdade porque o abuso sexual, o abuso e a violência contra as mulheres são cada vez mais denunciados parece esquecer que os algoritmos e a inteligência artificial que estão mudando nossas vidas também podem se tornar uma arma de discriminação em massa.


## Discriminação, preconceito, injustiça, o impacto do viés nos algoritmos

  
  Uma busca com as palavras Algoritmo e mulher em inglês no Google é suficiente para entender o problema principal (convido você a fazer a mesma busca mudando mulher por homem).

O primeiro resultado é um artigo intitulado "Incluindo mulheres em IA e algoritmos" da Fundação World Wide Web de Tim Berners-Lee, o criador da Internet e do hiperlink. A necessidade de publicar esse conteúdo já nos faz suspeitar que estamos diante de um problema. O artigo refere-se a um relatório que alerta sobre a dominação quase exclusiva dos homens no campo da inteligência artificial. Para reduzir essa lacuna, os autores do relatório propõem três recomendações: as mulheres, em primeiro lugar, devem ter um papel ativo na modelagem da nova geração de tecnologia; então os estados têm que implementar linhas de conduta para proteger as mulheres de algoritmos discriminatórios; e, finalmente, a pesquisa sobre o impacto dos algoritmos nas mulheres precisa ser fortalecida.


![Pesquisa no Google](/images/posts/google-search.jpg "Psquisa Google")


Os resultados a seguir dessa pesquisa confirmam a necessidade urgente de agir antes que a mesma história seja repetida. No artigo da revista Wired, Máquinas ensinadas por fotos aprendem uma visão sexista das mulheres, a existência da diferença de gênero é confirmada. Os resultados do estudo da Universidade da Virgínia, detalhados no artigo do El País Se está na cozinha, é uma mulher: como algoritmos reforçam preconceitos, mostram que após o treinamento um algoritmo com dois bancos de imagens que contêm apenas em um terço do total que um homem cozinha, o programa de computador deduz em 83% dos casos que uma pessoa cozinha é uma mulher. Outro exemplo de estudo, no mesmo artigo da revista Wired, é feito em 2016 por pesquisadores da Universidade de Boston e da Microsoft. Eles mostraram, coletando textos do Google News, o viés de gênero: quando a máquina treinada é solicitada a completar a seguinte frase: "O equivalente a 'homem é programar o que a mulher é para ...'" ("O homem é programador de computador como mulher é para X, "), responde" a dona de casa ".

Esta situação, segundo o The Guardian, não é nova. No artigo Por que o problema de gênero da tecnologia não é novidade, o jornal britânico revela as práticas da Amazônia gigante. Desde 2014, a tecnologia de automação da oferta de emprego desenvolvida pela empresa de Jeff Bezos tem sido principalmente treinada com currículo masculino. De fato, o sistema aprendeu que candidatos do sexo masculino eram preferíveis. A explicação é simples: os modelos de computador da Amazon foram treinados observando padrões nos currículos apresentados à empresa durante um período de 10 anos. A maioria veio de homens.


## Quando a mudança é esperada

  
  A identificação e modificação de um algoritmo tendencioso parece ser complexa. Isto é explicado, da revista de tecnologia MIT Technology Review, Karen Hao, em Como o viés algorítmico é produzido e por que é tão difícil pará-lo. O autor qualifica o papel dos dados. O viés, segundo Hao, pode existir muito antes que os dados sejam coletados e em outros processos. Existem três etapas principais em que o viés algorítmico ocorre. A definição do objetivo, a primeira etapa da elaboração de um algoritmo, corresponde à transformação de um conceito em uma fórmula matemática. Obviamente, as características são determinadas de acordo com os interesses da empresa que o algoritmo precisa. A próxima etapa é introduzir dados que possam revelar preconceitos e não refletir a realidade, como vimos antes com as imagens de homens cozinhando. Na última etapa, o computador tem que escolher um atributo, isto é, uma característica particular que ajudará a dar mais precisão à previsão do algoritmo. A escolha de um atributo ou o descarte de outro pode influenciar totalmente o viés.

É possível combater o preconceito? Muitos elementos devem ser levados em conta, assim como o contexto social, por exemplo. Convido você a descobrir como Joy Buolamwini, pesquisadora do MIT Media Lab, luta contra o viés dos algoritmos. Alerta de Spoiler: pode ser combatido com a ajuda de pessoas.


<div style="max-width:854px"><div style="position:relative;height:0;padding-bottom:56.25%"><iframe src="https://embed.ted.com/talks/lang/en/joy_buolamwini_how_i_m_fighting_bias_in_algorithms" width="854" height="480" style="position:absolute;left:0;top:0;width:100%;height:100%" frameborder="0" scrolling="no" allowfullscreen></iframe></div></div>



>“Este é o primeiro grande problema: a falta de mulheres cientistas e, o que é pior, a falta de um verdadeiro pensamento intersetorial por trás da criação de algoritmos.”


Essas palavras são de Ivana Bartoletti, profissional de proteção de dados e privacidade, que publicou no The Guardian Women devem agir agora, ou robôs projetados por homens tomarão conta de nossa vida, para denunciar a ditadura masculina por trás dos algoritmos e do falta de intervenção de instituições públicas na criação de algoritmos. Também é importante, diz o autor, questionar os resultados das decisões tomadas pelos algoritmos e pedir transparência. Bartoletti apela para uma melhor governança dos algoritmos onde as mulheres estão no centro e é por isso que as mulheres devem estar motivadas para serem treinadas em profissões tecnológicas.

>"A próxima luta para nós, mulheres, é garantir que a inteligência artificial não se torne a expressão máxima da masculinidade."

A educação é uma prioridade. Em L'absència de gnos à tecnologia, en cinc gràfics, a equipe StoryData visualiza o problema demonstrando a falta ainda muito alta de mulheres no mundo das TIC. As mulheres representam apenas 28% no setor de TIC.

![Evolução - Mulheres em IT](/images/posts/evolucio.jpg "Mulheres em T.I")


## Um Algoritimo Feminista

É uma pena, observar que os resultados da pesquisa no Google com as palavras Algoritmo e Mulher estão centrados, quase apenas na existência do viés de gênero nos algoritmos. É necessário enfatizar, no entanto, o aparecimento de uma referência importante à mulher que concebeu o primeiro algoritmo de Ada Lovelace (1815-1852). A memória do primeiro programador de computador é realizada anualmente na segunda terça-feira de outubro com o objetivo de promover a formação de mulheres em STEM (ciência, tecnologia, engenharia e matemática). Essa iniciativa é importante porque, como diz o diretor de tecnologia do Instituto de Ética e Tecnologias Emergentes, Marcelo Rinesi, na infância, as mulheres são informadas de que não são boas em disciplinas STEM e todos, a mídia, pais e mães e professores os encorajam a se interessar por atividades mais "femininas".

Não há dúvida de que a educação deve ser uma prioridade, assim como o empoderamento através da educação. É claro que, para gerar um algoritmo feminista, é necessário ter mulheres prontas. Nesta linha, Bartoletti, em seu artigo, alerta para outro impacto dos algoritmos e da inteligência artificial: segundo o Fórum Econômico Mundial, as mulheres são as que mais sofrerão com a automação do trabalho. O exemplo dos caixas é o mais fácil de entender. De acordo com um relatório do Cornerstone Capital Group, as mulheres representam 73% da profissão, de modo que 97% dos caixas perderão seus empregos por causa da automação. O mesmo relatório, explica o autor, prevê que as diferenças persistentes entre homens e mulheres nos campos da ciência, tecnologia, engenharia e matemática (Stem) nos próximos 15 anos também enfraquecerão a presença profissional das mulheres nessas áreas.

A ilusão da objetividade das máquinas e a infantilidade das mulheres são outros perigos que se somam à longa lista de obstáculos que aguardam as mulheres neste século XXI. Seria interessante dedicar outro artigo para refletir sobre esses perigos. Há muitos esforços que teremos que implantar ainda para que a feminização da sociedade seja eficaz. As tecnologias têm que tornar a vida mais fácil para nós e não colocar mais obstáculos em nosso caminho, mas parece que os homens continuam a moldar nosso futuro. Nós não podemos deixar a história se repetir. Nós continuamos com o combate.



